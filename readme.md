# Plataforma de Mantenimiento Predictivo Interactivo

Este proyecto es una simulaciÃ³n completa de un sistema distribuido de IoT Industrial, diseÃ±ado para el monitoreo en tiempo real, la detecciÃ³n de fallas y la intervenciÃ³n humana interactiva.

El sistema implementa una **arquitectura hÃ­brida** avanzada que separa el flujo de datos masivos (telemetrÃ­a) del flujo de decisiones (comandos humanos), utilizando **Kafka** y **RabbitMQ** para sus respectivas fortalezas.

El proyecto completo se levanta con un solo comando (`docker-compose up`) y consta de 10 contenedores: 2 brokers de mensajerÃ­a y 8 microservicios.



## ğŸš€ TecnologÃ­as Utilizadas

* **OrquestaciÃ³n:** Docker y Docker Compose
* **Flujo de Datos (Streaming):** Apache Kafka
* **Flujo de Decisiones (Colas):** RabbitMQ (con el plugin `rabbitmq_delayed_message_exchange`)
* **Backend (Microservicios):** Python
* **API y WebSockets:** FastAPI y Uvicorn
* **Frontend:** HTML5, CSS y JavaScript (vainilla)
* **Servidor Frontend:** Nginx

---

## ğŸ CÃ³mo Ejecutar el Proyecto

Para levantar la plataforma completa, solo necesitas tener Docker y Docker Compose instalados.

1.  **Clonar el Repositorio**
    ```bash
    git clone <URL_DE_TU_REPOSITORIO>
    cd proyecto_plataforma
    ```

2.  **Construir y Levantar los Contenedores**
    Este comando construirÃ¡ las 8 imÃ¡genes de los microservicios y levantarÃ¡ los 10 contenedores.
    ```bash
    docker-compose up --build
    ```

3.  **Acceder al Dashboard**
    Una vez que todos los contenedores estÃ©n corriendo, abre tu navegador y ve a:
    **[http://localhost/dashboard.html](http://localhost/dashboard.html)**

4.  **Detener el Sistema**
    Para detener todos los contenedores y eliminar la red, presiona `Ctrl+C` en la terminal y luego ejecuta:
    ```bash
    docker-compose down
    ```

---

## ğŸ—ï¸ Arquitectura y Flujo de Datos

El sistema se divide en dos flujos principales que corren en paralelo y se conectan a travÃ©s de un "puente".

### ğŸŒŠ Flujo 1: El Flujo de Datos (Kafka)
**PropÃ³sito:** Ingesta y anÃ¡lisis de telemetrÃ­a de alta velocidad. Es el responsable del panel izquierdo (**Estado de Planta**).

1.  **`sensor_producer` (Productor)**
    * Simula 10 sensores industriales.
    * Cada 6 segundos, ğŸ’™ **publica** 10 mensajes de vibraciÃ³n (JSON) al topic de Kafka `sensor_data`.
    * Usa el `sensor_id` como clave (key) para garantizar el procesamiento en orden.

2.  **`alert_detector` (Procesador Stateful)**
    * El "cerebro" del sistema. ğŸ’š **Consume** de `sensor_data`.
    * Mantiene un historial en memoria (ventana mÃ³vil) para cada sensor.
    * Aplica reglas de falla (ej. CrÃ­tica > 90, o 3 Advertencias > 75).
    * Si detecta una falla, ğŸ’™ **publica** una nueva alerta en los topics `alerts_critical` o `alerts_warning`.

3.  **`plant_monitor_backend` (Consumidor / Servidor WS)**
    * Un servicio hÃ­brido. ğŸ’š **Consume** de los 3 topics de Kafka (`sensor_data`, `alerts_warning`, `alerts_critical`).
    * Mantiene un estado general de la planta en memoria.
    * ğŸŒ **Expone** un WebSocket en el puerto `8081` (ruta `/ws`).
    * Cada vez que su estado interno cambia, envÃ­a el nuevo estado a todos los dashboards conectados.

### ğŸš¦ Flujo 2: El Flujo de Decisiones (RabbitMQ)
**PropÃ³sito:** Gestionar tareas complejas, enrutar a humanos y manejar acciones diferidas. Es el responsable del panel derecho (**Consola de Operador**).

4.  **`alert_router` (El Puente)**
    * El servicio que conecta ambos mundos.
    * ğŸ’š **Consume** las alertas de los topics de Kafka (`alerts_critical`, `alerts_warning`).
    * Enriquece el mensaje: genera el `alert_id` y las `options` (botones).
    * ğŸ’™ **Publica** la "solicitud de acciÃ³n" a un *Fanout Exchange* de RabbitMQ llamado `human_alerts`.

5.  **`operator_console_backend` (Consumidor / Servidor WS)**
    * ğŸ’š **Consume** los mensajes del *Fanout Exchange* `human_alerts`.
    * ğŸŒ **Expone** un WebSocket en el puerto `8082` (ruta `/ws`).
    * Tan pronto como recibe una alerta, la retransmite a todos los dashboards conectados para que se rendericen los botones.

6.  **`dashboard.html` (El Clic Humano)**
    * El operador ve la alerta y los botones en el panel derecho.
    * Al hacer clic, el JavaScript ğŸ’™ **envÃ­a** una peticiÃ³n `POST` al endpoint `/decide` del `action_dispatcher`.

7.  **`action_dispatcher` (API / Enrutador)**
    * ğŸŒ **Expone** la API en el puerto `8080` (ruta `POST /decide`).
    * Recibe la decisiÃ³n del humano.
    * ActÃºa como un enrutador inteligente de RabbitMQ. ğŸ’™ **Publica** el comando en la cola correcta:
        * `APAGADO_INMEDIATO` â†’ va a la cola `critical_actions_queue`.
        * `PROGRAMAR_MANTENIMIENTO_AHORA` â†’ va a la cola `maintenance_queue`.
        * `RECONOCER_Y_ESPERAR_24H` â†’ va al `delayed_maintenance_exchange` (para ser entregado a `maintenance_queue` 24 horas despuÃ©s).

8.  **`actuator_worker` (Consumidor)**
    * Un *worker* simple y dedicado.
    * ğŸ’š **Consume** tareas *solo* de la `critical_actions_queue`.
    * Simula el apagado de emergencia (imprime en el log).

9.  **`maintenance_worker` (Consumidor)**
    * Un *worker* simple y dedicado.
    * ğŸ’š **Consume** tareas de la `maintenance_queue`.
    * Recibe tanto las tareas inmediatas como las retrasadas de 24 horas.
    * Simula la creaciÃ³n de una orden de trabajo (imprime en el log).

---

## ğŸ”© Estructura de Microservicios (10 Contenedores)

| Servicio | Puerto (Host) | Imagen | PropÃ³sito |
| :--- | :--- | :--- | :--- |
| **Kafka** | `19092:19092` | `confluentinc/cp-kafka` | Broker de streaming para el flujo de datos. |
| **RabbitMQ** | `15672:15672` | `rabbitmq:management` | Broker de mensajerÃ­a para el flujo de decisiones. |
| **dashboard** | `80:80` | `nginx:alpine` | Sirve el `dashboard.html` estÃ¡tico. |
| **sensor_producer** | - | `(custom)` | (Python) ğŸ’™ Simula 10 sensores y publica en Kafka. |
| **alert_detector** | - | `(custom)` | (Python) ğŸ§  Consume de Kafka, aplica reglas, publica alertas en Kafka. |
| **plant_monitor_backend** | `8081:8081` | `(custom)` | (FastAPI) ğŸ’š Consume de Kafka, ğŸŒ sirve estado por WS 8081. |
| **alert_router** | - | `(custom)` | (Python) ğŸ§  Puente: Consume de Kafka, ğŸ’™ publica en RabbitMQ. |
| **operator_console_backend** | `8082:8082` | `(custom)` | (FastAPI) ğŸ’š Consume de RabbitMQ, ğŸŒ sirve acciones por WS 8082. |
| **action_dispatcher** | `8080:8080` | `(custom)` | (FastAPI) ğŸŒ Recibe `POST /decide`, ğŸ’™ enruta acciones a RabbitMQ. |
| **actuator_worker** | - | `(custom)` | (Python) ğŸ’š Consume de `critical_actions_queue`. |
| **maintenance_worker** | - | `(custom)` | (Python) ğŸ’š Consume de `maintenance_queue`. |

---

## ğŸ”§ ConfiguraciÃ³n Clave

### Tiempos
* **GeneraciÃ³n de Sensores:** El `sensor_producer` estÃ¡ configurado para enviar datos cada **6 segundos** (`producer.py`).
* **Retraso de 24H:** El `action_dispatcher` usa el plugin `rabbitmq_delayed_message_exchange` para encolar tareas con retraso.

### CORS
* El `action_dispatcher` estÃ¡ configurado con `CORSMiddleware` (`dispatcher.py`) para permitir que el `dashboard.html` (servido desde el puerto 80) pueda enviar la peticiÃ³n `POST` al puerto 8080.